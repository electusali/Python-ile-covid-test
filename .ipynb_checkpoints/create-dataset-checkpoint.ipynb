{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO8G-55Vjt-o"
   },
   "source": [
    "# Predict Covid-19 in X-ray images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5Uehnecjt-y"
   },
   "source": [
    "## Part 1: prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7RYYDQRjt-z"
   },
   "source": [
    "### Step 1: get the images with confirmed covid19\n",
    "Download and extract the [dataset](https://github.com/ieee8023/covid-chestxray-dataset) already prepared by [Dr. Joseph Cohen](https://josephpcohen.com/w/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1620554223197,
     "user": {
      "displayName": "Mustafa Tasci",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFWmf1vNvXNvhbOZ4ItGwll_jDqmfziZqtGb7lPQ=s64",
      "userId": "01883236927909768847"
     },
     "user_tz": -180
    },
    "id": "sk_FSA1bjt-0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1620554226973,
     "user": {
      "displayName": "Mustafa Tasci",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFWmf1vNvXNvhbOZ4ItGwll_jDqmfziZqtGb7lPQ=s64",
      "userId": "01883236927909768847"
     },
     "user_tz": -180
    },
    "id": "DKTOmr_Cjt-1"
   },
   "outputs": [],
   "source": [
    "covid_ds_path = '/home/henriklg/Downloads/covid-chestxray-dataset-master'\n",
    "covid_output_path = './dataset/covid'\n",
    "\n",
    "# Check if output folder exist, if not, create it\n",
    "directory = pathlib.Path(covid_output_path)\n",
    "if not directory.exists():\n",
    "        os.makedirs(covid_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 1161,
     "status": "error",
     "timestamp": 1620554232697,
     "user": {
      "displayName": "Mustafa Tasci",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFWmf1vNvXNvhbOZ4ItGwll_jDqmfziZqtGb7lPQ=s64",
      "userId": "01883236927909768847"
     },
     "user_tz": -180
    },
    "id": "LK75Qb_cjt-2",
    "outputId": "9fc207f0-33ca-4b99-e01c-abe750cae2ee"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c50d9ab0426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# construct the path to the metadata CSV file and load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcsvPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcovid_ds_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metadata.csv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcovid_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/henriklg/Downloads/covid-chestxray-dataset-master/metadata.csv'"
     ]
    }
   ],
   "source": [
    "# construct the path to the metadata CSV file and load it\n",
    "csvPath = os.path.sep.join([covid_ds_path, \"metadata.csv\"])\n",
    "df = pd.read_csv(csvPath)\n",
    "covid_count = 0\n",
    "\n",
    "# loop over the rows of the COVID-19 data frame\n",
    "for (i, row) in df.iterrows():\n",
    "    # if (1) the current case is not COVID-19 or (2) this is not\n",
    "    # a 'PA' view, then ignore the row\n",
    "    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n",
    "        continue\n",
    "\n",
    "    # build the path to the input image file\n",
    "    imagePath = os.path.sep.join([covid_ds_path, \"images\", row[\"filename\"]])\n",
    "\n",
    "    # if the input image file does not exist (there are some errors in\n",
    "    # the COVID-19 metadeta file), ignore the row\n",
    "    if not os.path.exists(imagePath):\n",
    "        continue\n",
    "\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = row[\"filename\"].split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([covid_output_path, filename])\n",
    "    covid_count += 1\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)\n",
    "\n",
    "print (\"Succsessfuly copied over {} covid images!\".format(covid_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VXyvlN3jt-4"
   },
   "source": [
    "## Step 2: get the normal x-ray images\n",
    "To find X-ray images of healthy patients I used this [Kaggle dataset](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia). Download and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DLV91t1jt-4"
   },
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfZ-oq7mjt-5"
   },
   "outputs": [],
   "source": [
    "normal_ds_path = '/home/henriklg/Downloads/chest-xray-pneumonia/chest_xray/chest_xray'\n",
    "normal_output_path = 'dataset/normal'\n",
    "normal_count = covid_count # grab as many normal images as we have covid images (in my case 56)\n",
    "\n",
    "# Check if output folder exist, if not, create it\n",
    "directory = pathlib.Path(normal_output_path)\n",
    "if not directory.exists():\n",
    "        os.makedirs(normal_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DLuDeVwjt-5",
    "outputId": "321ba7de-e9bf-41fd-f6fb-817b675df244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succsessfuly copied over 56 normal images!\n"
     ]
    }
   ],
   "source": [
    "# grab all training image paths from the Kaggle X-ray dataset\n",
    "basePath = os.path.sep.join([normal_ds_path, \"train\", \"NORMAL\"])\n",
    "imagePaths = list(paths.list_images(normal_ds_path))\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:normal_count]\n",
    "count = 0\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([normal_output_path, filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)\n",
    "    count += 1\n",
    "\n",
    "print (\"Succsessfuly copied over {} normal images!\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCp_XwE6jt-6"
   },
   "source": [
    "### Now we have created a dataset with one folder for healthy patients and one for sick patients. Next: train the model!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "create-dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
